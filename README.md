# Can Generative AI Protect Queries? Balancing Privacy and Retrieval

This repository is the official implementation of the paper "Can Generative AI Protect Queries? Balancing Privacy and Retrieval". The paper is accepted at ECIR 2025.

This project explores the ability of generative AI, particularly Large Language Models (LLMs), to protect user queries while maintaining effective information retrieval. As users increasingly provide sensitive and detailed prompts, balancing privacy with retrieval performance is critical. The study evaluates confusion-based techniques for query protection, analyzing their effectiveness in safeguarding privacy and their impact on retrieval quality. This research aims to contribute to the development of more privacy-aware and efficient information retrieval systems.

You can run the experiments with ```main_ir.py```, analyze the results with ```analyze_results.py```, and generate the figures with ```plot_results.py```, and
plot our latex tables with ```latex_table_generation.py```. We also include the reformulations
we used and the results they produced in the ```local_data``` folder.