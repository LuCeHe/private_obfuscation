# -*- coding: utf-8 -*-
"""latex_bm25_moto_generation_blessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZCgbFO56oZVerLYVPxbdYytpxOf70ckf
"""

import warnings
import os
import pandas as pd

warnings.simplefilter(action='ignore', category=FutureWarning)


WORKDIR = '/content'


from google.colab import drive
drive.mount('/content/drive')

PODATADIR = '/content/drive/MyDrive/'

# Metrics of interest
metrics_oi_ = [
    'map',
    'nDCG@10',
    'nDCG@100',
    'mean_jaccard_similarity',
    'mean_szymkiewicz_similarity',
    'mean_bert_similarity',
]


pandas_path = os.path.join(PODATADIR, 'result_data.csv')
df = pd.read_csv(pandas_path)


df = df.round(3)


df = df[df['retriever'] == 'BM25%100>>MonoT5']

all_reformulations = df['reformulation'].unique()
all_datasets = df['dataset_name'].unique()

print("', '".join(all_reformulations))
print(all_datasets)

# New columns: reformulation
refs = [
    'none',
    'wordnet',
    'cmp_e1', 'cmp_e5', 'cmp_e50',
    'mah_e1', 'mah_e5', 'mah_e50',
    'vik_e1', 'vik_e5', 'vik_e50',
    'vikcmp_e1', 'vikcmp_e5', 'vikcmp_e50',
    'vikm_e1', 'vikm_e5', 'vikm_e50',
    'chatgpt3p5_prompt1', 'chatgpt3p5_prompt2', 'chatgpt3p5_prompt3',
    'chatgpt3p5_promptM1k1', 'chatgpt3p5_promptM1k3', 'chatgpt3p5_promptM1k5',
    'chatgpt3p5_promptM2k1', 'chatgpt3p5_promptM2k3', 'chatgpt3p5_promptM2k5',
    'chatgpt3p5_promptM3k1', 'chatgpt3p5_promptM3k3', 'chatgpt3p5_promptM3k5',
]

refs[refs.index('none')] = 'NONE'

def bold_and_underline(table, metrics_oi, prefix_metric=''):
    pm = prefix_metric
    similarity_metrics = ['mean_jaccard_similarity', 'mean_szymkiewicz_similarity', 'mean_bert_similarity']

    for m in metrics_oi:
        # Get best and second best
        table[f'{pm}{m}'] = table[f'{pm}{m}'].astype(float)

        # Handle similarity metrics differently
        if m in similarity_metrics:
            # Find minimum for similarity metrics
            best_metric = table[f'{pm}{m}'].min()
            # Sort in ascending order
            second_best_metric = table[f'{pm}{m}'].sort_values().unique()[1]
        else:
            # Find maximum for other metrics
            best_metric = table[f'{pm}{m}'].max()
            # Sort in descending order
            second_best_metric = table[f'{pm}{m}'].sort_values(ascending=False).unique()[1]

        print(f"Metric: {m}")
        print(f"Best: {best_metric:.3f}, Second best: {second_best_metric:.3f}")

        # Bold best metric
        table[f'{pm}{m}'] = table[f'{pm}{m}'].apply(
            lambda x: f'\\textbf{{{x:.3f}}}' if str(x) == str(best_metric) else x
        )
        # Underline second best metric
        table[f'{pm}{m}'] = table[f'{pm}{m}'].apply(
            lambda x: f'\\underline{{{x:.3f}}}' if str(x) == str(second_best_metric)
            else f'{float(x):.3f}' if isinstance(x, float) else x
        )

    return table

def create_table(df, refs, datasets_oi, metrics_oi):
    sdf = df.copy()

    rows = []
    row_0 = [''] + [f'd{i}' for i, dataset in enumerate(datasets_oi) for _ in metrics_oi]
    rows.append(row_0)
    row_1 = ['reformulator'] + [metric for _ in datasets_oi for metric in metrics_oi]
    rows.append(row_1)

    for ref in refs:
        row = [ref]
        for dataset in datasets_oi:
            dsdf = sdf[(sdf['dataset_name'] == dataset)]
            dsdf = bold_and_underline(dsdf, metrics_oi)

            for metric in metrics_oi:
                mask = dsdf['reformulation'].eq(ref)
                v = dsdf[mask][metric].values
                v = v[0] if len(v) > 0 else '-'
                row.append(v)
        rows.append(row)

    # Convert to DataFrame and then to LaTeX
    sdf = pd.DataFrame(rows)
    latex = sdf.to_latex(index=False, header=False)
    latex = latex.replace('nDCG@10', r'\textbf{\textrm{nDCG}}_{10}').replace('nDCG@100', r'\textbf{\textrm{nDCG}}_{100}')

    latex = f"""
\\begin{{table}}[H]
\\centering
\\resizebox{{\\columnwidth}}{{!}}{{%
{latex}
}}
\\caption{{Effect on BM25 and MonoT5}}
\\label{{tab:table1}}
\\end{{table}}
"""

    for ref in refs:

        latex = latex.replace(ref, f'\\textbf{{{ref}}}')

    # Cleaning names
    #latex = latex.replace('chatgpt3p5_prompt', r'$\textbf{GPT}_{P_}$')

    latex = latex.replace('chatgpt3p5_prompt', r'\textrm{GPT}')

    latex = latex.replace(r'\textrm{GPT}1', r'\textrm{GPT}$_{\mathbf{P}1}$')
    latex = latex.replace(r'\textrm{GPT}2', r'\textrm{GPT}$_{\mathbf{P}2}$')
    latex = latex.replace(r'\textrm{GPT}3', r'\textrm{GPT}$_{\mathbf{P}3}$')

    latex = latex.replace('M1k1', '$_{\mathbf{P}4}^{k=1}$').replace('M1k3', '$_{\mathbf{P}4}^{k=3}$').replace('M1k5', '$_{\mathbf{P}4}^{k=5}$')
    latex = latex.replace('M2k1', '$_{\mathbf{P}5}^{k=1}$').replace('M2k3', '$_{\mathbf{P}5}^{k=3}$').replace('M2k5', '$_{\mathbf{P}5}^{k=5}$')
    latex = latex.replace('M3k1', '$_{\mathbf{P}6}^{k=1}$').replace('M3k3', '$_{\mathbf{P}6}^{k=3}$').replace('M3k5', '$_{\mathbf{P}6}^{k=5}$')

    latex = latex.replace('wordnet', 'WordNet')
    latex = latex.replace('reformulator', '\\textbf{QM}')

    metrics_with_at = [m for m in metrics_oi if '@' in m]
    for m in metrics_with_at:
        latex = latex.replace(m, f'\\makecell{{\\textbf{{{m.split("@")[0]}}} \\\\ \\textbf{{@{m.split("@")[1]}}} }}')

    for m in metrics_oi:
        latex = latex.replace(m, f'\\textbf{{{m}}}')

    for i, d in enumerate(datasets_oi):
        d_string = ' & '.join([f'd{i}'] * len(metrics_oi))
        latex = latex.replace(d_string, f'\multicolumn{{{len(metrics_oi)}}}{{c}}{{{d}}} ')

    latex = latex.replace('irds:', '').replace('msmarco-document/', '')
    latex = latex.replace('beir/', '').replace('/test', '')
    latex = latex.replace('nfcorpus', 'NFCorpus')
    latex = latex.replace('trec-covid', 'TREC-COVID')
    latex = latex.replace('webis-touche2020/v2', r'\textit{Touch√©}')

    latex = latex.replace('mean_jaccard_similarity', r'\textrm{JI}')
    latex = latex.replace('mean_szymkiewicz_similarity', r'\textrm{SSC}')
    latex = latex.replace('mean_bert_similarity', r'$ \textrm{CS}_{\textrm{B}} $')
    latex = latex.replace('map', 'MAP')

    latex = latex.replace('}0', '0}').replace('} 0', '0}').replace('vik\\textbf{', '\\textbf{vik')

    # Updating GPT naming for prompts
    latex = latex.replace('pM1', 'p4-').replace('pM2', 'p5-').replace('pM3', 'p6-')

    for i in [1, 3, 5]:
        latex = latex.replace(f'-k{i}', f'$_{{k={i}}}$')

    latex = latex.replace('vikcmp', r'\textrm{VC}').replace('vikm', r'\textrm{VM}').replace('vik', r'\textrm{V}')
    latex = latex.replace('cmp', r'\textrm{CMP}').replace('mah', r'\textrm{M}')

    for i in [1, 50, 5]:
        latex = latex.replace(f'_e{i}', f'$_{{{i}}}$')

    latex = latex.replace('$0', '0$').replace('nan', '-')

    return latex

# Specify the datasets of interest
datasets_oi = [
    'irds:beir/nfcorpus/test',
    'irds:beir/trec-covid',
    'irds:beir/webis-touche2020/v2',
]

# Create the LaTeX table
all_latexes = create_table(df.copy(), refs, datasets_oi, metrics_oi_)
print(all_latexes)